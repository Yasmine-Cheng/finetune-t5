{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Shivanandroy/T5-Finetuning-PyTorch/blob/main/notebook/T5_Fine_tuning_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bbwl6E1E205R",
    "outputId": "7ab0c99b-8f25-4f48-a74b-ba54bf93c6bf"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\r\n",
    "!pip install transformers\r\n",
    "!pip install rich[jupyter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设dataframe中有source_text和target_text两列\n",
    "source_lengths = df[\"prev_resp\"].apply(len)\n",
    "target_lengths = df[\"next_resp\"].apply(len)\n",
    "\n",
    "# 基本统计信息\n",
    "print(\"源文本长度统计：\")\n",
    "print(f\"平均长度: {source_lengths.mean()}\")\n",
    "print(f\"最大长度: {source_lengths.max()}\")\n",
    "print(f\"最小长度: {source_lengths.min()}\")\n",
    "print(f\"中位数长度: {source_lengths.median()}\")\n",
    "\n",
    "# 同样分析目标文本\n",
    "print(\"\\n目标文本长度统计：\")\n",
    "print(f\"平均长度: {target_lengths.mean()}\")\n",
    "print(f\"最大长度: {target_lengths.max()}\")\n",
    "print(f\"最小长度: {target_lengths.min()}\")\n",
    "print(f\"中位数长度: {target_lengths.median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYfBicZQ59Jf"
   },
   "outputs": [],
   "source": [
    "df[\"next_resp\"] = \"next response: \"+df[\"next_resp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['prev_resp', 'next_resp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console=Console(record=True)\n",
    "def display_df(df):\n",
    "    console=Console()\n",
    "    table = Table(Column(\"source_text\", justify=\"center\" ), Column(\"target_text\", justify=\"center\"), title=\"Sample Data\",pad_edge=False, box=box.ASCII)\n",
    "    for i, row in enumerate(df.values.tolist()):\n",
    "        table.add_row(row[0], row[1])\n",
    "    console.print(table)\n",
    "training_logger = Table(Column(\"Epoch\", justify=\"center\" ), Column(\"Steps\", justify=\"center\"), Column(\"Loss\", justify=\"center\"), title=\"Training Status\",pad_edge=False, box=box.ASCII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlYaKW9h4ai_"
   },
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\r\n",
    "from torch import cuda\r\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vLQPGAn4v17"
   },
   "outputs": [],
   "source": [
    "class YourDataSetClass(Dataset):\r\n",
    "  \"\"\"\r\n",
    "  Creating a custom dataset for reading the dataset and \r\n",
    "  loading it into the dataloader to pass it to the neural network for finetuning the model\r\n",
    "\r\n",
    "  \"\"\"\r\n",
    "\r\n",
    "  def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\r\n",
    "    self.tokenizer = tokenizer\r\n",
    "    self.data = dataframe\r\n",
    "    self.source_len = source_len\r\n",
    "    self.summ_len = target_len\r\n",
    "    self.target_text = self.data[target_text]\r\n",
    "    self.source_text = self.data[source_text]\r\n",
    "\r\n",
    "  def __len__(self):\r\n",
    "    return len(self.target_text)\r\n",
    "\r\n",
    "  def __getitem__(self, index):\r\n",
    "    source_text = str(self.source_text[index])\r\n",
    "    target_text = str(self.target_text[index])\r\n",
    "\r\n",
    "    #cleaning data so as to ensure data is in string type\r\n",
    "    source_text = ' '.join(source_text.split())\r\n",
    "    target_text = ' '.join(target_text.split())\r\n",
    "\r\n",
    "    source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\r\n",
    "    target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\r\n",
    "\r\n",
    "    source_ids = source['input_ids'].squeeze()\r\n",
    "    source_mask = source['attention_mask'].squeeze()\r\n",
    "    target_ids = target['input_ids'].squeeze()\r\n",
    "    target_mask = target['attention_mask'].squeeze()\r\n",
    "\r\n",
    "    return {\r\n",
    "        'source_ids': source_ids.to(dtype=torch.long), \r\n",
    "        'source_mask': source_mask.to(dtype=torch.long), \r\n",
    "        'target_ids': target_ids.to(dtype=torch.long),\r\n",
    "        'target_ids_y': target_ids.to(dtype=torch.long)\r\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nkj6wIMt40RK"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\r\n",
    "\r\n",
    "  \"\"\"\r\n",
    "  Function to be called for training with the parameters passed from main function\r\n",
    "\r\n",
    "  \"\"\"\r\n",
    "\r\n",
    "  model.train()\r\n",
    "  for _,data in enumerate(loader, 0):\r\n",
    "    y = data['target_ids'].to(device, dtype = torch.long)\r\n",
    "    y_ids = y[:, :-1].contiguous()\r\n",
    "    lm_labels = y[:, 1:].clone().detach()\r\n",
    "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\r\n",
    "    ids = data['source_ids'].to(device, dtype = torch.long)\r\n",
    "    mask = data['source_mask'].to(device, dtype = torch.long)\r\n",
    "\r\n",
    "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\r\n",
    "    loss = outputs[0]\r\n",
    "\r\n",
    "    if _%10==0:\r\n",
    "      training_logger.add_row(str(epoch), str(_), str(loss))\r\n",
    "      console.print(training_logger)\r\n",
    "\r\n",
    "    optimizer.zero_grad()\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "\n",
    "  \"\"\"\n",
    "  Function to evaluate model for predictions\n",
    "\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  predictions = []\n",
    "  actuals = []\n",
    "  with torch.no_grad():\n",
    "      for _, data in enumerate(loader, 0):\n",
    "          y = data['target_ids'].to(device, dtype = torch.long)\n",
    "          ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "          mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "          generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=150, \n",
    "              min_length=10,\n",
    "              num_beams= 5,\n",
    "              repetition_penalty=2.5, \n",
    "              no_repeat_ngram_size=2,\n",
    "              top_k=50,\n",
    "              top_p=0.95,\n",
    "              length_penalty=1.0, \n",
    "              early_stopping=True\n",
    "              )\n",
    "          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "          if _%10==0:\n",
    "              console.print(f'Completed {_}')\n",
    "\n",
    "          predictions.extend(preds)\n",
    "          actuals.extend(target)\n",
    "  return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw4RW_qO4_8T"
   },
   "outputs": [],
   "source": [
    "def T5Trainer(dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\" ):\r\n",
    "  \r\n",
    "  \"\"\"\r\n",
    "  T5 trainer\r\n",
    "\r\n",
    "  \"\"\"\r\n",
    "\r\n",
    "  # Set random seeds and deterministic pytorch for reproducibility\r\n",
    "  torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\r\n",
    "  np.random.seed(model_params[\"SEED\"]) # numpy random seed\r\n",
    "  torch.backends.cudnn.deterministic = True\r\n",
    "\r\n",
    "  # logging\r\n",
    "  console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\r\n",
    "\r\n",
    "  # tokenzier for encoding the text\r\n",
    "  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\r\n",
    "\r\n",
    "  # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \r\n",
    "  # Further this model is sent to device (GPU/TPU) for using the hardware.\r\n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\r\n",
    "  model = model.to(device)\r\n",
    "  \r\n",
    "  # logging\r\n",
    "  console.log(f\"[Data]: Reading data...\\n\")\r\n",
    "\r\n",
    "  # Importing the raw dataset\r\n",
    "  dataframe = dataframe[[source_text,target_text]]\r\n",
    "  display_df(dataframe.head(2))\r\n",
    "\r\n",
    "  \r\n",
    "  # Creation of Dataset and Dataloader\r\n",
    "  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \r\n",
    "  train_size = 0.8\r\n",
    "  train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\r\n",
    "  val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\r\n",
    "  train_dataset = train_dataset.reset_index(drop=True)\r\n",
    "\r\n",
    "  console.print(f\"FULL Dataset: {dataframe.shape}\")\r\n",
    "  console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\r\n",
    "  console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\r\n",
    "\r\n",
    "\r\n",
    "  # Creating the Training and Validation dataset for further creation of Dataloader\r\n",
    "  training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\r\n",
    "  val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_SOURCE_TEXT_LENGTH\"], model_params[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\r\n",
    "\r\n",
    "\r\n",
    "  # Defining the parameters for creation of dataloaders\r\n",
    "  train_params = {\r\n",
    "      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\r\n",
    "      'shuffle': True,\r\n",
    "      'num_workers': 0\r\n",
    "      }\r\n",
    "\r\n",
    "\r\n",
    "  val_params = {\r\n",
    "      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\r\n",
    "      'shuffle': False,\r\n",
    "      'num_workers': 0\r\n",
    "      }\r\n",
    "\r\n",
    "\r\n",
    "  # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\r\n",
    "  training_loader = DataLoader(training_set, **train_params)\r\n",
    "  val_loader = DataLoader(val_set, **val_params)\r\n",
    "\r\n",
    "\r\n",
    "  # Defining the optimizer that will be used to tune the weights of the network in the training session. \r\n",
    "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\r\n",
    "\r\n",
    "\r\n",
    "  # Training loop\r\n",
    "  console.log(f'[Initiating Fine Tuning]...\\n')\r\n",
    "\r\n",
    "  for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\r\n",
    "      train(epoch, tokenizer, model, device, training_loader, optimizer)\r\n",
    "      \r\n",
    "  console.log(f\"[Saving Model]...\\n\")\r\n",
    "  #Saving the model after training\r\n",
    "  path = os.path.join(output_dir, \"model_files\")\r\n",
    "  model.save_pretrained(path)\r\n",
    "  tokenizer.save_pretrained(path)\r\n",
    "\r\n",
    "\r\n",
    "  # evaluating test dataset\r\n",
    "  console.log(f\"[Initiating Validation]...\\n\")\r\n",
    "  for epoch in range(model_params[\"VAL_EPOCHS\"]):\r\n",
    "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\r\n",
    "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\r\n",
    "    final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\r\n",
    "  \r\n",
    "  console.save_text(os.path.join(output_dir,'logs.txt'))\r\n",
    "  \r\n",
    "  console.log(f\"[Validation Completed.]\\n\")\r\n",
    "  console.print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\")\r\n",
    "  console.print(f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\r\n",
    "  console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"MODEL\":\"google/mt5-base\",    # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\":8,          # training batch size\n",
    "    \"VALID_BATCH_SIZE\":8,          # validation batch size\n",
    "    \"TRAIN_EPOCHS\":3,              # number of training epochs\n",
    "    \"VAL_EPOCHS\":1,                # number of validation epochs\n",
    "    \"LEARNING_RATE\":1e-4,          # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\":100,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\":100,   # max length of target text\n",
    "    \"SEED\": 42                     # set seed for reproducibility \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qijZoYeI55fM",
    "outputId": "69c68bb6-4fba-47e4-9e74-73f2579aa3c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T5Trainer(dataframe=df, source_text=\"prev_resp\", target_text=\"next_resp\", model_params=model_params, output_dir=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XD2qL87Wsn19"
   },
   "outputs": [],
   "source": [
    "predict = pd.read_csv('./outputs/predictions.csv', index_col=0)\n",
    "predict.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM+sqU2Hgca8RM/Wjv+9kvQ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "T5 Fine tuning with PyTorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
